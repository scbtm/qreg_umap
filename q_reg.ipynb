{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiQuantileRegressor:\n",
    "    def __init__(self, n_quantiles = 10, #number of quantiles to be used\n",
    "                 hyperparams:dict = {}, #model hyperparameters\n",
    "                 rs:int = 1, #random seed\n",
    "                 categorical_features:list = [], \n",
    "                 numerical_features:list = [], \n",
    "                 ):\n",
    "        \n",
    "        self.model = None\n",
    "        #cuantos cuantiles queremos\n",
    "        self.n_quantiles = n_quantiles\n",
    "        self.quantiles = [q/n_quantiles for q in range(1, n_quantiles)]\n",
    "        #Se necesita definir este string para llamar a la funcion de perdida del modelo\n",
    "        self.quantile_str = str(self.quantiles).replace('[','').replace(']','').replace(' ', '')\n",
    "\n",
    "        hyperparams['loss_function'] = f'MultiQuantile:alpha={self.quantile_str}'\n",
    "        hyperparams['random_seed'] = rs\n",
    "\n",
    "        self.hyperparams = hyperparams\n",
    "        self.predictive_features = categorical_features + numerical_features\n",
    "        self.categorical_features = categorical_features\n",
    "        self.numerical_features = numerical_features\n",
    "        \n",
    "    def instantiate_model(self):\n",
    "        self.model = CatBoostRegressor(**self.hyperparams)\n",
    "\n",
    "    def fit(self,\n",
    "            xtrain:pd.DataFrame, \n",
    "            ytrain:pd.Series,\n",
    "            xval:pd.DataFrame = None,\n",
    "            yval:pd.Series = None,\n",
    "            verbose = 0):\n",
    "        \n",
    "        N_train = len(xtrain)\n",
    "        train_pool = Pool(xtrain, ytrain, cat_features=self.categorical_features)\n",
    "                \n",
    "        self.instantiate_model()\n",
    "\n",
    "        metrics = dict()\n",
    "\n",
    "        if (xval is not None) & (yval is not None):\n",
    "            N_val = len(xval)\n",
    "            val_pool = Pool(xval, yval, cat_features=self.categorical_features) \n",
    "            self.model.fit(train_pool, \n",
    "                           eval_set=val_pool, \n",
    "                           verbose=verbose, \n",
    "                           plot=False, \n",
    "                           use_best_model=True)\n",
    "            \n",
    "            #train metrics\n",
    "            preds = self.model.predict(xtrain)\n",
    "            point_preds = preds.mean(axis=1)\n",
    "            mape = mean_absolute_percentage_error(ytrain, point_preds)\n",
    "            mean_spread = np.mean(np.abs(preds[:,-1] - preds[:,0]))\n",
    "            standard_deviation = np.std(preds, axis=1).mean()\n",
    "            loss_fn = self.model.get_best_score()['learn'][f'MultiQuantile:alpha={self.quantile_str}']\n",
    "            train_preds = pd.DataFrame(preds, columns=[f'pred_{q}' for q in self.quantiles])\n",
    "\n",
    "            metrics['training'] = dict()\n",
    "            metrics['training']['mape'] = mape\n",
    "            metrics['training']['mean_spread'] = mean_spread\n",
    "            metrics['training']['standard_deviation'] = standard_deviation\n",
    "            metrics['training']['loss_fn'] = loss_fn\n",
    "            \n",
    "            #Validation performance\n",
    "            preds = self.model.predict(xval)\n",
    "            point_preds = preds.mean(axis=1)\n",
    "\n",
    "            mape = mean_absolute_percentage_error(yval, point_preds)\n",
    "            mean_spread = np.mean(preds[:,-1] - preds[:,0])\n",
    "            standard_deviation = np.std(preds, axis=1).mean()\n",
    "            loss_fn = self.model.get_best_score()['validation'][f'MultiQuantile:alpha={self.quantile_str}']\n",
    "            val_preds = pd.DataFrame(preds, columns=[f'pred_{q}' for q in self.quantiles])\n",
    "\n",
    "            metrics['validation'] = dict()\n",
    "            metrics['validation']['mape'] = mape\n",
    "            metrics['validation']['mean_spread'] = mean_spread\n",
    "            metrics['validation']['standard_deviation'] = standard_deviation\n",
    "            metrics['validation']['loss_fn'] = loss_fn\n",
    "\n",
    "            metadata = dict()\n",
    "            metadata['quantiles'] = self.quantiles\n",
    "            metadata['quantile_str'] = self.quantile_str\n",
    "            metadata['hyperparams'] = self.hyperparams\n",
    "            metadata['full_hyperparams'] = self.model.get_all_params()\n",
    "\n",
    "            metadata['categorical_features'] = self.categorical_features\n",
    "            metadata['numerical_features'] = self.numerical_features\n",
    "            metadata['train_size'] = N_train\n",
    "            metadata['val_size'] = N_val\n",
    "\n",
    "            predictions = dict()\n",
    "            predictions['train'] = train_preds\n",
    "            predictions['val'] = val_preds\n",
    "\n",
    "            return predictions, metrics, metadata\n",
    "            \n",
    "\n",
    "        else:\n",
    "            self.model.fit(train_pool, \n",
    "                           verbose=verbose, \n",
    "                           plot=False, \n",
    "                           use_best_model=True)\n",
    "            \n",
    "            #train metrics\n",
    "            preds = self.model.predict(xtrain)\n",
    "            point_preds = preds.mean(axis=1)\n",
    "            mape = mean_absolute_percentage_error(ytrain, point_preds)\n",
    "            mean_spread = np.mean(preds[:,-1] - preds[:,0])\n",
    "            standard_deviation = np.std(preds, axis=1).mean()\n",
    "            loss_fn = self.model.get_best_score()['learn'][f'MultiQuantile:alpha={self.quantile_str}']\n",
    "            train_preds = pd.DataFrame(preds, columns=[f'pred_{q}' for q in self.quantiles])\n",
    "\n",
    "            metrics['training'] = dict()\n",
    "            metrics['training']['mape'] = mape\n",
    "            metrics['training']['mean_spread'] = mean_spread\n",
    "            metrics['training']['standard_deviation'] = standard_deviation\n",
    "            metrics['training']['loss_fn'] = loss_fn\n",
    "\n",
    "            metadata = dict()\n",
    "            metadata['quantiles'] = self.quantiles\n",
    "            metadata['quantile_str'] = self.quantile_str\n",
    "            metadata['hyperparams'] = self.hyperparams\n",
    "            metadata['full_hyperparams'] = self.model.get_all_params()\n",
    "            metadata['categorical_features'] = self.categorical_features\n",
    "            metadata['numerical_features'] = self.numerical_features\n",
    "            metadata['train_size'] = N_train\n",
    "\n",
    "            predictions = dict()\n",
    "            predictions['train'] = train_preds\n",
    "\n",
    "            return predictions, metrics, metadata\n",
    "        \n",
    "    def predict(self, xtest:pd.DataFrame, return_point_preds = True, return_preds_as_df = False):\n",
    "        preds = self.model.predict(xtest)\n",
    "        point_preds = preds.mean(axis=1)            \n",
    "\n",
    "        if return_preds_as_df:\n",
    "            preds = pd.DataFrame(preds, columns=[f'pred_{q}' for q in self.quantiles])\n",
    "\n",
    "        if return_point_preds:\n",
    "            return preds, point_preds\n",
    "        \n",
    "        else:\n",
    "            return preds\n",
    "    \n",
    "    def evaluate(self, ytrue:pd.Series, point_preds, preds):\n",
    "        mape = mean_absolute_percentage_error(ytrue, point_preds)\n",
    "        mean_spread = np.mean(preds[:,-1] - preds[:,0])\n",
    "        standard_deviation = np.std(preds, axis=1).mean()\n",
    "\n",
    "        metrics = dict()\n",
    "        metrics['mape'] = mape\n",
    "        metrics['mean_spread'] = mean_spread\n",
    "        metrics['standard_deviation'] = standard_deviation\n",
    "        return metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Num0</th>\n",
       "      <th>Cat0</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat2</th>\n",
       "      <th>Cat3</th>\n",
       "      <th>Cat4</th>\n",
       "      <th>Cat5</th>\n",
       "      <th>Num1</th>\n",
       "      <th>MonotonicNeg0</th>\n",
       "      <th>...</th>\n",
       "      <th>MonotonicNeg8</th>\n",
       "      <th>Num22</th>\n",
       "      <th>MonotonicNeg9</th>\n",
       "      <th>Num23</th>\n",
       "      <th>MonotonicNeg10</th>\n",
       "      <th>Num24</th>\n",
       "      <th>Num25</th>\n",
       "      <th>Num26</th>\n",
       "      <th>Num27</th>\n",
       "      <th>Num28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>6780</td>\n",
       "      <td>7</td>\n",
       "      <td>66</td>\n",
       "      <td>494</td>\n",
       "      <td>583</td>\n",
       "      <td>109</td>\n",
       "      <td>0.020319</td>\n",
       "      <td>0.066393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059776</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.019978</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.019833</td>\n",
       "      <td>0.220801</td>\n",
       "      <td>0.088723</td>\n",
       "      <td>0.316292</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>41183</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>472</td>\n",
       "      <td>650</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.078344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010702</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.847325</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.811932</td>\n",
       "      <td>0.017582</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>52666</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>403</td>\n",
       "      <td>665</td>\n",
       "      <td>109</td>\n",
       "      <td>0.017192</td>\n",
       "      <td>0.074828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343446</td>\n",
       "      <td>0.019208</td>\n",
       "      <td>0.084036</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.018917</td>\n",
       "      <td>0.996521</td>\n",
       "      <td>0.249741</td>\n",
       "      <td>0.175907</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2451</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>514</td>\n",
       "      <td>583</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.066093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014197</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.847325</td>\n",
       "      <td>0.077754</td>\n",
       "      <td>0.086481</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>27005</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>189</td>\n",
       "      <td>219</td>\n",
       "      <td>109</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.066301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.046838</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>0.296760</td>\n",
       "      <td>0.046695</td>\n",
       "      <td>0.131224</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827042</th>\n",
       "      <td>0</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>11473</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>309</td>\n",
       "      <td>583</td>\n",
       "      <td>109</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.066346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.174054</td>\n",
       "      <td>0.055488</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827043</th>\n",
       "      <td>0</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>10343</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>163</td>\n",
       "      <td>109</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.075443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086576</td>\n",
       "      <td>0.024275</td>\n",
       "      <td>0.037737</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.847325</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.953237</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827044</th>\n",
       "      <td>0</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>33709</td>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "      <td>480</td>\n",
       "      <td>583</td>\n",
       "      <td>109</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.063947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.220801</td>\n",
       "      <td>0.091011</td>\n",
       "      <td>0.204470</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827045</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51422</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>218</td>\n",
       "      <td>332</td>\n",
       "      <td>109</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.064556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.017842</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.996521</td>\n",
       "      <td>0.307104</td>\n",
       "      <td>0.202947</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827046</th>\n",
       "      <td>2</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>47494</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>122</td>\n",
       "      <td>583</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.068294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.847325</td>\n",
       "      <td>0.077754</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2827047 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target      Num0   Cat0  Cat1  Cat2  Cat3  Cat4  Cat5      Num1   \n",
       "0             1  0.078947   6780     7    66   494   583   109  0.020319  \\\n",
       "1             1  0.039474  41183     8    58   472   650   109  0.000608   \n",
       "2             0  0.144737  52666     5    32   403   665   109  0.017192   \n",
       "3             0  0.000000   2451     8    25   514   583   109  0.000863   \n",
       "4             0  0.105263  27005     9    50   189   219   109  0.003540   \n",
       "...         ...       ...    ...   ...   ...   ...   ...   ...       ...   \n",
       "2827042       0  0.092105  11473     2    42   309   583   109  0.005911   \n",
       "2827043       0  0.131579  10343     8    58    61   163   109  0.009518   \n",
       "2827044       0  0.118421  33709     7    89   480   583   109  0.002931   \n",
       "2827045       0  0.000000  51422     5     4   218   332   109  0.002770   \n",
       "2827046       2  0.065789  47494     8    25   122   583   109  0.000645   \n",
       "\n",
       "         MonotonicNeg0  ...  MonotonicNeg8     Num22  MonotonicNeg9     Num23   \n",
       "0             0.066393  ...       0.059776  0.089834       0.019978  0.057514  \\\n",
       "1             0.078344  ...       0.010702  0.004125       0.011961  0.057514   \n",
       "2             0.074828  ...       0.343446  0.019208       0.084036  0.057514   \n",
       "3             0.066093  ...       0.014197  0.089834       0.000866  0.057514   \n",
       "4             0.066301  ...       0.015038  0.046838       0.006607  0.057514   \n",
       "...                ...  ...            ...       ...            ...       ...   \n",
       "2827042       0.066346  ...       0.016001  0.089834       0.005824  0.057514   \n",
       "2827043       0.075443  ...       0.086576  0.024275       0.037737  0.057514   \n",
       "2827044       0.063947  ...       0.008424  0.089834       0.002794  0.057514   \n",
       "2827045       0.064556  ...       0.007381  0.017842       0.012611  0.057514   \n",
       "2827046       0.068294  ...       0.012095  0.089834       0.000675  0.057514   \n",
       "\n",
       "         MonotonicNeg10     Num24     Num25     Num26     Num27     Num28  \n",
       "0              0.019833  0.220801  0.088723  0.316292  0.999997  0.999994  \n",
       "1              0.000727  0.847325  0.999976  0.811932  0.017582  0.999994  \n",
       "2              0.018917  0.996521  0.249741  0.175907  0.004534  0.999994  \n",
       "3              0.000859  0.847325  0.077754  0.086481  0.999997  0.999994  \n",
       "4              0.003469  0.296760  0.046695  0.131224  0.008043  0.999994  \n",
       "...                 ...       ...       ...       ...       ...       ...  \n",
       "2827042        0.005781  0.174054  0.055488  0.006744  0.999997  0.999994  \n",
       "2827043        0.010570  0.847325  0.999976  0.953237  0.014712  0.999994  \n",
       "2827044        0.002774  0.220801  0.091011  0.204470  0.999997  0.999994  \n",
       "2827045        0.002647  0.996521  0.307104  0.202947  0.006410  0.999994  \n",
       "2827046        0.000670  0.847325  0.077754  0.011311  0.999997  0.999994  \n",
       "\n",
       "[2827047 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummy data (este dataset se tarda un poco en cargar)\n",
    "from catboost.datasets import monotonic1\n",
    "\n",
    "monotonic1_train, monotonic1_test = monotonic1()\n",
    "\n",
    "monotonic1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Num0</th>\n",
       "      <th>Cat0</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat2</th>\n",
       "      <th>Cat3</th>\n",
       "      <th>Cat4</th>\n",
       "      <th>Cat5</th>\n",
       "      <th>Num1</th>\n",
       "      <th>MonotonicNeg0</th>\n",
       "      <th>...</th>\n",
       "      <th>MonotonicNeg8</th>\n",
       "      <th>Num22</th>\n",
       "      <th>MonotonicNeg9</th>\n",
       "      <th>Num23</th>\n",
       "      <th>MonotonicNeg10</th>\n",
       "      <th>Num24</th>\n",
       "      <th>Num25</th>\n",
       "      <th>Num26</th>\n",
       "      <th>Num27</th>\n",
       "      <th>Num28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>21599</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>390</td>\n",
       "      <td>583</td>\n",
       "      <td>109</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.154136</td>\n",
       "      <td>0.108807</td>\n",
       "      <td>0.214663</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>29748</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>171</td>\n",
       "      <td>681</td>\n",
       "      <td>51</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>0.083899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045563</td>\n",
       "      <td>0.185618</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.054323</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.312872</td>\n",
       "      <td>0.192753</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>10423</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "      <td>113</td>\n",
       "      <td>583</td>\n",
       "      <td>109</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.080834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.220801</td>\n",
       "      <td>0.052217</td>\n",
       "      <td>0.023535</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>48892</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>284</td>\n",
       "      <td>583</td>\n",
       "      <td>109</td>\n",
       "      <td>0.038159</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018629</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.038117</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.037840</td>\n",
       "      <td>0.296760</td>\n",
       "      <td>0.251499</td>\n",
       "      <td>0.131705</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5832</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>427</td>\n",
       "      <td>176</td>\n",
       "      <td>58</td>\n",
       "      <td>0.017210</td>\n",
       "      <td>0.078808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019977</td>\n",
       "      <td>0.142491</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>0.135979</td>\n",
       "      <td>0.007114</td>\n",
       "      <td>0.312872</td>\n",
       "      <td>0.192753</td>\n",
       "      <td>0.210305</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.001604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706756</th>\n",
       "      <td>0</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>32633</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>425</td>\n",
       "      <td>271</td>\n",
       "      <td>109</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.074214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.224415</td>\n",
       "      <td>0.163928</td>\n",
       "      <td>0.362164</td>\n",
       "      <td>0.029672</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706757</th>\n",
       "      <td>1</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>1095</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>345</td>\n",
       "      <td>371</td>\n",
       "      <td>109</td>\n",
       "      <td>0.009101</td>\n",
       "      <td>0.085608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120729</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>0.847325</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.996935</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706758</th>\n",
       "      <td>0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>14327</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>219</td>\n",
       "      <td>67</td>\n",
       "      <td>109</td>\n",
       "      <td>0.033079</td>\n",
       "      <td>0.083003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.033095</td>\n",
       "      <td>0.312872</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.060711</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706759</th>\n",
       "      <td>1</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>28225</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>425</td>\n",
       "      <td>496</td>\n",
       "      <td>112</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.086557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.008614</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.011725</td>\n",
       "      <td>0.224415</td>\n",
       "      <td>0.163928</td>\n",
       "      <td>0.362164</td>\n",
       "      <td>0.021229</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706760</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>10758</td>\n",
       "      <td>12</td>\n",
       "      <td>131</td>\n",
       "      <td>436</td>\n",
       "      <td>583</td>\n",
       "      <td>109</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015311</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.154136</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.367132</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706761 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target      Num0   Cat0  Cat1  Cat2  Cat3  Cat4  Cat5      Num1   \n",
       "0            0  0.144737  21599    12    80   390   583   109  0.001302  \\\n",
       "1            0  0.013158  29748     0    47   171   681    51  0.008405   \n",
       "2            0  0.144737  10423     7    86   113   583   109  0.004338   \n",
       "3            0  0.092105  48892     9    77   284   583   109  0.038159   \n",
       "4            0  0.000000   5832     0    47   427   176    58  0.017210   \n",
       "...        ...       ...    ...   ...   ...   ...   ...   ...       ...   \n",
       "706756       0  0.131579  32633     1   125   425   271   109  0.000868   \n",
       "706757       1  0.039474   1095     8    58   345   371   109  0.009101   \n",
       "706758       0  0.052632  14327     0    28   219    67   109  0.033079   \n",
       "706759       1  0.026316  28225     1   125   425   496   112  0.001540   \n",
       "706760       0  0.026316  10758    12   131   436   583   109  0.002075   \n",
       "\n",
       "        MonotonicNeg0  ...  MonotonicNeg8     Num22  MonotonicNeg9     Num23   \n",
       "0            0.084337  ...       0.008192  0.089834       0.001356  0.057514  \\\n",
       "1            0.083899  ...       0.045563  0.185618       0.004185  0.054323   \n",
       "2            0.080834  ...       0.009681  0.089834       0.004277  0.057514   \n",
       "3            0.082278  ...       0.018629  0.089834       0.038117  0.057514   \n",
       "4            0.078808  ...       0.019977  0.142491       0.010450  0.135979   \n",
       "...               ...  ...            ...       ...            ...       ...   \n",
       "706756       0.074214  ...       0.012292  0.008261       0.007550  0.057514   \n",
       "706757       0.085608  ...       0.120729  0.022934       0.035432  0.057514   \n",
       "706758       0.083003  ...       0.028889  0.233300       0.012965  0.057514   \n",
       "706759       0.086557  ...       0.025086  0.015957       0.008614  0.005506   \n",
       "706760       0.082034  ...       0.015311  0.089834       0.002088  0.057514   \n",
       "\n",
       "        MonotonicNeg10     Num24     Num25     Num26     Num27     Num28  \n",
       "0             0.001346  0.154136  0.108807  0.214663  0.999997  0.999994  \n",
       "1             0.008992  0.312872  0.192753  0.170700  0.001924  0.000186  \n",
       "2             0.004246  0.220801  0.052217  0.023535  0.999997  0.999994  \n",
       "3             0.037840  0.296760  0.251499  0.131705  0.999997  0.999994  \n",
       "4             0.007114  0.312872  0.192753  0.210305  0.008542  0.001604  \n",
       "...                ...       ...       ...       ...       ...       ...  \n",
       "706756        0.000796  0.224415  0.163928  0.362164  0.029672  0.999994  \n",
       "706757        0.009408  0.847325  0.999976  0.996935  0.003780  0.999994  \n",
       "706758        0.033095  0.312872  0.029615  0.060711  0.008261  0.999994  \n",
       "706759        0.011725  0.224415  0.163928  0.362164  0.021229  0.000230  \n",
       "706760        0.002072  0.154136  0.001360  0.367132  0.999997  0.999994  \n",
       "\n",
       "[706761 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monotonic1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic1_train_sample = monotonic1_train.sample(frac=0.1, random_state=42)\n",
    "monotonic1_test_sample = monotonic1_test.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = monotonic1_train_sample['Num26']\n",
    "xtrain = monotonic1_train_sample.drop('Num26', axis=1)\n",
    "yval = monotonic1_test_sample['Num26']\n",
    "xval = monotonic1_test_sample.drop('Num26', axis=1)\n",
    "\n",
    "categorical_features = [_ for _ in xtrain.columns if 'Cat' in _]\n",
    "numerical_features = [_ for _ in xtrain.columns if 'Cat' not in _]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = MultiQuantileRegressor(n_quantiles=10, \n",
    "                                   hyperparams={'iterations': 250}, #En la práctica usaríamos entre 750-2000 iteraciones/estimadores\n",
    "                                   rs = 123,\n",
    "                                   categorical_features=categorical_features, #No necesitamos preprocesarlas en catboost, solo indicarlas\n",
    "                                   numerical_features=numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0882395\ttest: 0.0878919\tbest: 0.0878919 (0)\ttotal: 572ms\tremaining: 2m 22s\n",
      "50:\tlearn: 0.0242622\ttest: 0.0241722\tbest: 0.0241722 (50)\ttotal: 21s\tremaining: 1m 22s\n",
      "100:\tlearn: 0.0093594\ttest: 0.0093459\tbest: 0.0093459 (100)\ttotal: 41.1s\tremaining: 1m\n",
      "150:\tlearn: 0.0059229\ttest: 0.0059240\tbest: 0.0059240 (150)\ttotal: 1m 1s\tremaining: 40.6s\n",
      "200:\tlearn: 0.0048773\ttest: 0.0048808\tbest: 0.0048808 (200)\ttotal: 1m 23s\tremaining: 20.4s\n",
      "249:\tlearn: 0.0045001\ttest: 0.0045036\tbest: 0.0045036 (249)\ttotal: 1m 45s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.004503581401\n",
      "bestIteration = 249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions, metrics, metadata = regressor.fit(xtrain, ytrain, xval, yval, verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0.1</th>\n",
       "      <th>pred_0.2</th>\n",
       "      <th>pred_0.3</th>\n",
       "      <th>pred_0.4</th>\n",
       "      <th>pred_0.5</th>\n",
       "      <th>pred_0.6</th>\n",
       "      <th>pred_0.7</th>\n",
       "      <th>pred_0.8</th>\n",
       "      <th>pred_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.952450</td>\n",
       "      <td>0.952522</td>\n",
       "      <td>0.952676</td>\n",
       "      <td>0.952837</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>0.953247</td>\n",
       "      <td>0.953251</td>\n",
       "      <td>0.953353</td>\n",
       "      <td>0.953563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018539</td>\n",
       "      <td>0.023862</td>\n",
       "      <td>0.028049</td>\n",
       "      <td>0.032283</td>\n",
       "      <td>0.036063</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.045450</td>\n",
       "      <td>0.052822</td>\n",
       "      <td>0.068108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.810938</td>\n",
       "      <td>0.811246</td>\n",
       "      <td>0.811127</td>\n",
       "      <td>0.810999</td>\n",
       "      <td>0.811164</td>\n",
       "      <td>0.811715</td>\n",
       "      <td>0.811803</td>\n",
       "      <td>0.812020</td>\n",
       "      <td>0.812346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.366907</td>\n",
       "      <td>0.366903</td>\n",
       "      <td>0.367679</td>\n",
       "      <td>0.367209</td>\n",
       "      <td>0.368257</td>\n",
       "      <td>0.368597</td>\n",
       "      <td>0.367057</td>\n",
       "      <td>0.366053</td>\n",
       "      <td>0.366186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120830</td>\n",
       "      <td>0.125480</td>\n",
       "      <td>0.128630</td>\n",
       "      <td>0.130801</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.141840</td>\n",
       "      <td>0.146606</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.156097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282700</th>\n",
       "      <td>0.015281</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>0.021556</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>0.027246</td>\n",
       "      <td>0.030640</td>\n",
       "      <td>0.035859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282701</th>\n",
       "      <td>0.306689</td>\n",
       "      <td>0.309225</td>\n",
       "      <td>0.312171</td>\n",
       "      <td>0.312760</td>\n",
       "      <td>0.314339</td>\n",
       "      <td>0.314840</td>\n",
       "      <td>0.319822</td>\n",
       "      <td>0.324156</td>\n",
       "      <td>0.338221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282702</th>\n",
       "      <td>0.193409</td>\n",
       "      <td>0.198554</td>\n",
       "      <td>0.202074</td>\n",
       "      <td>0.213860</td>\n",
       "      <td>0.217458</td>\n",
       "      <td>0.225361</td>\n",
       "      <td>0.248109</td>\n",
       "      <td>0.263456</td>\n",
       "      <td>0.330609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282703</th>\n",
       "      <td>0.804705</td>\n",
       "      <td>0.808478</td>\n",
       "      <td>0.814280</td>\n",
       "      <td>0.812195</td>\n",
       "      <td>0.816745</td>\n",
       "      <td>0.817979</td>\n",
       "      <td>0.812250</td>\n",
       "      <td>0.811387</td>\n",
       "      <td>0.811431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282704</th>\n",
       "      <td>0.171613</td>\n",
       "      <td>0.174779</td>\n",
       "      <td>0.182596</td>\n",
       "      <td>0.185077</td>\n",
       "      <td>0.186569</td>\n",
       "      <td>0.186628</td>\n",
       "      <td>0.185720</td>\n",
       "      <td>0.198417</td>\n",
       "      <td>0.214420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282705 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_0.1  pred_0.2  pred_0.3  pred_0.4  pred_0.5  pred_0.6  pred_0.7   \n",
       "0       0.952450  0.952522  0.952676  0.952837  0.953052  0.953247  0.953251  \\\n",
       "1       0.018539  0.023862  0.028049  0.032283  0.036063  0.040002  0.045450   \n",
       "2       0.810938  0.811246  0.811127  0.810999  0.811164  0.811715  0.811803   \n",
       "3       0.366907  0.366903  0.367679  0.367209  0.368257  0.368597  0.367057   \n",
       "4       0.120830  0.125480  0.128630  0.130801  0.134454  0.141840  0.146606   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "282700  0.015281  0.019551  0.021556  0.022117  0.024689  0.027473  0.027246   \n",
       "282701  0.306689  0.309225  0.312171  0.312760  0.314339  0.314840  0.319822   \n",
       "282702  0.193409  0.198554  0.202074  0.213860  0.217458  0.225361  0.248109   \n",
       "282703  0.804705  0.808478  0.814280  0.812195  0.816745  0.817979  0.812250   \n",
       "282704  0.171613  0.174779  0.182596  0.185077  0.186569  0.186628  0.185720   \n",
       "\n",
       "        pred_0.8  pred_0.9  \n",
       "0       0.953353  0.953563  \n",
       "1       0.052822  0.068108  \n",
       "2       0.812020  0.812346  \n",
       "3       0.366053  0.366186  \n",
       "4       0.150841  0.156097  \n",
       "...          ...       ...  \n",
       "282700  0.030640  0.035859  \n",
       "282701  0.324156  0.338221  \n",
       "282702  0.263456  0.330609  \n",
       "282703  0.811387  0.811431  \n",
       "282704  0.198417  0.214420  \n",
       "\n",
       "[282705 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mape': 731590260.3628671,\n",
       "  'mean_spread': 0.04437777083561119,\n",
       "  'standard_deviation': 0.01357121850753662,\n",
       "  'loss_fn': 0.004500068860674632},\n",
       " {'mape': 0.4268282301324402,\n",
       "  'mean_spread': 0.04483031199867458,\n",
       "  'standard_deviation': 0.013718164062011156,\n",
       "  'loss_fn': 0.004503581400626787})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['training'], metrics['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonic1_test_sample2 = monotonic1_test.sample(frac=0.1, random_state=1)\n",
    "ytest = monotonic1_test_sample['Num26']\n",
    "xtest = monotonic1_test_sample.drop('Num26', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion de un conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, point_preds = regressor.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1778116 , 0.19446191, 0.20890857, ..., 0.2334156 , 0.23840805,\n",
       "        0.26457867],\n",
       "       [0.61730667, 0.61523327, 0.62484295, ..., 0.71335756, 0.72919267,\n",
       "        0.74927218],\n",
       "       [0.35906382, 0.36120366, 0.36240401, ..., 0.36816183, 0.37018748,\n",
       "        0.36911051],\n",
       "       ...,\n",
       "       [0.80470473, 0.80847841, 0.81428019, ..., 0.81224959, 0.81138668,\n",
       "        0.81143129],\n",
       "       [0.10778458, 0.11543631, 0.11931929, ..., 0.12657087, 0.12786601,\n",
       "        0.13798772],\n",
       "       [0.0023956 , 0.0043332 , 0.00648543, ..., 0.01570386, 0.02036936,\n",
       "        0.03048355]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22253445, 0.66907684, 0.36560461, ..., 0.8121611 , 0.12231927,\n",
       "       0.01234167])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 0.4268282301324402,\n",
       " 'mean_spread': 0.04483031199867458,\n",
       " 'standard_deviation': 0.013718164062011156}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.evaluate(ytest, point_preds, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podemos regresar las predicciones como dataframe para otros análisis\n",
    "preds, point_preds = regressor.predict(xtest, return_preds_as_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0.1</th>\n",
       "      <th>pred_0.2</th>\n",
       "      <th>pred_0.3</th>\n",
       "      <th>pred_0.4</th>\n",
       "      <th>pred_0.5</th>\n",
       "      <th>pred_0.6</th>\n",
       "      <th>pred_0.7</th>\n",
       "      <th>pred_0.8</th>\n",
       "      <th>pred_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.177812</td>\n",
       "      <td>0.194462</td>\n",
       "      <td>0.208909</td>\n",
       "      <td>0.225354</td>\n",
       "      <td>0.230197</td>\n",
       "      <td>0.229675</td>\n",
       "      <td>0.233416</td>\n",
       "      <td>0.238408</td>\n",
       "      <td>0.264579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617307</td>\n",
       "      <td>0.615233</td>\n",
       "      <td>0.624843</td>\n",
       "      <td>0.638184</td>\n",
       "      <td>0.660316</td>\n",
       "      <td>0.673986</td>\n",
       "      <td>0.713358</td>\n",
       "      <td>0.729193</td>\n",
       "      <td>0.749272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.359064</td>\n",
       "      <td>0.361204</td>\n",
       "      <td>0.362404</td>\n",
       "      <td>0.365241</td>\n",
       "      <td>0.367757</td>\n",
       "      <td>0.367312</td>\n",
       "      <td>0.368162</td>\n",
       "      <td>0.370187</td>\n",
       "      <td>0.369111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.996288</td>\n",
       "      <td>0.996320</td>\n",
       "      <td>0.996378</td>\n",
       "      <td>0.996465</td>\n",
       "      <td>0.996516</td>\n",
       "      <td>0.996536</td>\n",
       "      <td>0.996600</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>0.996921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.043839</td>\n",
       "      <td>0.050687</td>\n",
       "      <td>0.063207</td>\n",
       "      <td>0.068423</td>\n",
       "      <td>0.070597</td>\n",
       "      <td>0.071955</td>\n",
       "      <td>0.074997</td>\n",
       "      <td>0.076585</td>\n",
       "      <td>0.078932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70671</th>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.012752</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>0.020534</td>\n",
       "      <td>0.026371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70672</th>\n",
       "      <td>0.200989</td>\n",
       "      <td>0.200992</td>\n",
       "      <td>0.201048</td>\n",
       "      <td>0.200917</td>\n",
       "      <td>0.201159</td>\n",
       "      <td>0.201257</td>\n",
       "      <td>0.201373</td>\n",
       "      <td>0.201784</td>\n",
       "      <td>0.204127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70673</th>\n",
       "      <td>0.804705</td>\n",
       "      <td>0.808478</td>\n",
       "      <td>0.814280</td>\n",
       "      <td>0.812195</td>\n",
       "      <td>0.816745</td>\n",
       "      <td>0.817979</td>\n",
       "      <td>0.812250</td>\n",
       "      <td>0.811387</td>\n",
       "      <td>0.811431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70674</th>\n",
       "      <td>0.107785</td>\n",
       "      <td>0.115436</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>0.120728</td>\n",
       "      <td>0.122612</td>\n",
       "      <td>0.122568</td>\n",
       "      <td>0.126571</td>\n",
       "      <td>0.127866</td>\n",
       "      <td>0.137988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70675</th>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.010225</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>0.015704</td>\n",
       "      <td>0.020369</td>\n",
       "      <td>0.030484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70676 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred_0.1  pred_0.2  pred_0.3  pred_0.4  pred_0.5  pred_0.6  pred_0.7   \n",
       "0      0.177812  0.194462  0.208909  0.225354  0.230197  0.229675  0.233416  \\\n",
       "1      0.617307  0.615233  0.624843  0.638184  0.660316  0.673986  0.713358   \n",
       "2      0.359064  0.361204  0.362404  0.365241  0.367757  0.367312  0.368162   \n",
       "3      0.996288  0.996320  0.996378  0.996465  0.996516  0.996536  0.996600   \n",
       "4      0.043839  0.050687  0.063207  0.068423  0.070597  0.071955  0.074997   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "70671  0.005218  0.006261  0.009067  0.011995  0.012752  0.013784  0.015958   \n",
       "70672  0.200989  0.200992  0.201048  0.200917  0.201159  0.201257  0.201373   \n",
       "70673  0.804705  0.808478  0.814280  0.812195  0.816745  0.817979  0.812250   \n",
       "70674  0.107785  0.115436  0.119319  0.120728  0.122612  0.122568  0.126571   \n",
       "70675  0.002396  0.004333  0.006485  0.008891  0.010225  0.012188  0.015704   \n",
       "\n",
       "       pred_0.8  pred_0.9  \n",
       "0      0.238408  0.264579  \n",
       "1      0.729193  0.749272  \n",
       "2      0.370187  0.369111  \n",
       "3      0.996710  0.996921  \n",
       "4      0.076585  0.078932  \n",
       "...         ...       ...  \n",
       "70671  0.020534  0.026371  \n",
       "70672  0.201784  0.204127  \n",
       "70673  0.811387  0.811431  \n",
       "70674  0.127866  0.137988  \n",
       "70675  0.020369  0.030484  \n",
       "\n",
       "[70676 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar si el valor verdadero está dentro del 'intervalo de confianza' (predicción)\n",
    "preds['Num26'] = ytest.values\n",
    "preds['in_interval'] = preds.apply(lambda x: x['Num26'] >= x['pred_0.1'] and x['Num26'] <= x['pred_0.9'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in_interval\n",
       "True     0.833833\n",
       "False    0.166167\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['in_interval'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
